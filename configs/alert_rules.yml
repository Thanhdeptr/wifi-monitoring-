groups:
  - name: network_alerts
    rules:
      # SNMP Exporter Alerts
      - alert: HighCPUUsage
        expr: avg by (instance, gw) (hrProcessorLoad) > 85
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage detected"
          description: "Device ({{ $labels.gw }}) CPU usage is {{ $value }}%"
          
      - alert: HighMemoryUsage
        expr: 100 * (sum by (instance, gw) (hrStorageUsed{hrStorageType="1.3.6.1.2.1.25.2.1.2"} * hrStorageAllocationUnits{hrStorageType="1.3.6.1.2.1.25.2.1.2"}) / sum by (instance, device, gw) (hrStorageSize{hrStorageType="1.3.6.1.2.1.25.2.1.2"} * hrStorageAllocationUnits{hrStorageType="1.3.6.1.2.1.25.2.1.2"})) > 80
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage detected"
          description: "Device {{ $labels.device }} ({{ $labels.gw }}) memory usage is {{ $value }}%"
          
      - alert: InterfaceHighTraffic
        expr: (rate(ifHCInOctets[5m]) * 8) > 500000000 or (rate(ifHCOutOctets[5m]) * 8) > 500000000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High interface traffic detected"
          description: "Interface {{ $labels.ifName }} on {{ $labels.device }} has high traffic: In={{ $value }}bps"
          
      - alert: InterfaceDown
        expr: |
          (max by (instance, device, gw, ifName, ifIndex) (ifOperStatus{ifOperStatus="up"}) == 0)
          and on (instance, device, gw, ifName, ifIndex)
          (sum by (instance, device, gw, ifName, ifIndex) (changes(ifOperStatus{ifOperStatus="up"}[5m])) > 0)
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Interface just went down"
          description: "Interface {{ $labels.ifName }} on {{ $labels.device }} ({{ $labels.gw }}) transitioned from UP to DOWN"
          
      - alert: InterfaceHighErrors
        expr: rate(ifInErrors[1m]) > 1 or rate(ifOutErrors[1m]) > 1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High interface errors detected"
          description: "Interface {{ $labels.ifName }} on {{ $labels.device }} has high error rate: {{ $value }} errors/sec"

      # Omada Exporter Alerts (dựa trên metric thực tế)
      - alert: OmadaHighCPUUsage
        expr: max by (device, device_type, site) (omada_device_cpu_percentage{job="omada-exporter"}) > 85
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Omada device high CPU usage"
          description: "Device {{ $labels.device }} ({{ $labels.device_type }}) at site {{ $labels.site }} CPU {{ $value }}%"

      - alert: OmadaHighMemoryUsage
        expr: max by (device, device_type, site) (omada_device_mem_percentage{job="omada-exporter"}) > 80
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Omada device high memory usage"
          description: "Device {{ $labels.device }} ({{ $labels.device_type }}) at site {{ $labels.site }} memory {{ $value }}%"

      - alert: OmadaDeviceHighTraffic
        expr: (rate(omada_device_download{job="omada-exporter"}[5m]) * 8 > 5e8)
          or (rate(omada_device_upload{job="omada-exporter"}[5m]) * 8 > 5e8)
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Omada device high traffic"
          description: "Device {{ $labels.device }} ({{ $labels.device_type }}) traffic {{ $value }}bps"

      - alert: OmadaControllerHighStorageUsage
        expr: 100 * (omada_controller_storage_used_bytes{job="omada-exporter"}) / (omada_controller_storage_used_bytes{job="omada-exporter"} + omada_controller_storage_available_bytes{job="omada-exporter"}) > 85
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Omada controller high storage usage"
          description: "Controller {{ $labels.controller_name }} storage usage {{ $value }}% at site {{ $labels.site }}"

  - name: speedtest_alerts
    rules:
      - alert: SlowDownloadSpeed
        expr: speedtest_download_bits_per_second < 20000000  # 20 Mbps
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Slow download speed detected"
          description: "WAN {{ $labels.line }} ({{ $labels.gateway }}) download speed is {{ $value | humanize }}bps ({{ $value | humanize1024 }}B/s)"
          
      - alert: SlowUploadSpeed
        expr: speedtest_upload_bits_per_second < 20000000  # 20 Mbps
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Slow upload speed detected"
          description: "WAN {{ $labels.line }} ({{ $labels.gateway }}) upload speed is {{ $value | humanize }}bps ({{ $value | humanize1024 }}B/s)"
          
      - alert: HighPingLatency
        expr: speedtest_ping_latency_milliseconds > 100  # 100ms
        for: 3m
        labels:
          severity: warning
        annotations:
          summary: "High ping latency detected"
          description: "WAN {{ $labels.line }} ({{ $labels.gateway }}) ping latency is {{ $value }}ms"
          
      - alert: SpeedtestFailed
        expr: speedtest_download_bits_per_second == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Speedtest failed"
          description: "WAN {{ $labels.line }} ({{ $labels.gateway }}) speedtest failed - no data received"

  - name: system_alerts
    rules:
      - alert: PrometheusDown
        expr: up{job="prometheus"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Prometheus is down"
          description: "Prometheus monitoring system is not responding"
          
      - alert: SNMPExporterDown
        expr: up{job="snmp-exporter"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "SNMP Exporter is down"
          description: "SNMP Exporter is not responding - network monitoring may be affected"
          
      - alert: GrafanaDown
        expr: up{job="grafana"} == 0
        for: 5s
        labels:
          severity: warning
        annotations:
          summary: "Grafana is down"
          description: "Grafana dashboard is not accessible"
